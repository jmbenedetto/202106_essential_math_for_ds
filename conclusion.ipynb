{
 "cells": [{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import ticker\n",
    "\n",
    "# Display options\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "np.set_printoptions(threshold=30)\n",
    "\n",
    "# Plots style\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['xtick.color'] = '#A9A9A9'\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.color'] = '#A9A9A9'\n",
    "\n",
    "mpl.rcParams['grid.color'] = '#ffffff'\n",
    "\n",
    "mpl.rcParams['axes.facecolor'] = '#ffffff'\n",
    "\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.bottom'] = False\n",
    "\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler(color=['#2EBCE7', '#84EE29', '#FF8177'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\var{{\\text{Var}}} % Variance\n",
    "\\def\\corr{{\\text{Corr}}} % Correlation\n",
    "\\def\\cov{{\\text{Cov}}} % Covariance\n",
    "\\def\\expval{{}}\n",
    "\\newcommand\\norm[1]{\\lVert#1\\rVert} % norm\n",
    "\\def\\setR{{\\rm I\\!R}} % Sets\n",
    "\\def\\rx{{\\textrm{X}}} % Scalar random variables\n",
    "\\def\\ry{{\\textrm{Y}}}\n",
    "\\def\\rz{{\\textrm{Z}}}\n",
    "\\def\\rvx{{\\textbf{X}}} % Vector random variables\n",
    "\\def\\rvy{{\\textbf{Y}}}\n",
    "\\def\\rvz{{\\textbf{Z}}}\n",
    "\\def\\vtheta{{\\boldsymbol{\\theta}}} % Vectors\n",
    "\\def\\va{{\\boldsymbol{a}}}\n",
    "\\def\\vb{{\\boldsymbol{b}}}\n",
    "\\def\\vi{{\\boldsymbol{i}}}\n",
    "\\def\\vj{{\\boldsymbol{j}}}\n",
    "\\def\\vp{{\\boldsymbol{p}}}\n",
    "\\def\\vq{{\\boldsymbol{q}}}\n",
    "\\def\\vu{{\\boldsymbol{u}}}\n",
    "\\def\\vv{{\\boldsymbol{v}}}\n",
    "\\def\\vw{{\\boldsymbol{w}}}\n",
    "\\def\\vx{{\\boldsymbol{x}}}\n",
    "\\def\\vy{{\\boldsymbol{y}}}\n",
    "\\def\\vz{{\\boldsymbol{z}}}\n",
    "\\def\\evu{{u}} % Elements of vectors\n",
    "\\def\\evv{{v}}\n",
    "\\def\\evw{{w}}\n",
    "\\def\\evx{{x}}\n",
    "\\def\\evy{{y}}\n",
    "\\def\\evz{{z}}\n",
    "\\def\\mA{{\\boldsymbol{A}}} % Matrices\n",
    "\\def\\mB{{\\boldsymbol{B}}}\n",
    "\\def\\mC{{\\boldsymbol{C}}}\n",
    "\\def\\mD{{\\boldsymbol{D}}}\n",
    "\\def\\mI{{\\boldsymbol{I}}}\n",
    "\\def\\mQ{{\\boldsymbol{Q}}}\n",
    "\\def\\mS{{\\boldsymbol{S}}}\n",
    "\\def\\mT{{\\boldsymbol{T}}}\n",
    "\\def\\mU{{\\boldsymbol{U}}}\n",
    "\\def\\mV{{\\boldsymbol{V}}}\n",
    "\\def\\mW{{\\boldsymbol{W}}}\n",
    "\\def\\mX{{\\boldsymbol{X}}}\n",
    "\\def\\mLambda{{\\boldsymbol{\\Lambda}}}\n",
    "\\def\\mSigma{{\\boldsymbol{\\Sigma}}}\n",
    "\\def\\emA{{A}} % Elements of matrices\n",
    "\\def\\emB{{B}}\n",
    "\\def\\emX{{X}}\n",
    "\\def\\tT{{T}} % Transformations\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Conclusion\n",
    "==========\n",
    "\n",
    "Congratulation! You reach the end of this book, designed to help you\n",
    "improve your math skills and increase your efficiency in data science\n",
    "and machine learning. I must admit that these last chapters were not\n",
    "easy, but they’ll give you solid foundations for data related fields.\n",
    "\n",
    "Learning the topics covered here will help you to understand what’s\n",
    "under the hood of tools that you may already use. Let’s take for\n",
    "instance the Support Vector Machines algorithm (SVM) for binary\n",
    "classification. If you read how it works, you’ll see that the goal is to\n",
    "find hyperplanes separating the data with a maximum distance between\n",
    "them. To follow the description, you’ll need for instance to understand\n",
    "vector equations, or the concept of distance expressed as norms. The\n",
    "purpose of *Essential Math for Data Science* is to give you all you need\n",
    "to dig more deeply about the algorithms you’re interested in.\n",
    "\n",
    "For this reason, the core math topics that you’ll need are covered in\n",
    "this book: calculus, statistics and probability theory, and linear\n",
    "algebra. You can note that there is an emphasis on linear algebra: this\n",
    "content is more suited for people wanting to become data scientist or\n",
    "machine learning scientist than data analyst (for instance, data\n",
    "analysts might need more details about inference, samples\n",
    "vs. population, etc.) .\n",
    "\n",
    "As a side note, I think that even a short acculturation to the math\n",
    "concepts, the symbols, and the vocabulary encountered in data science\n",
    "and machine learning can stimulate your practice in the field and help\n",
    "you to dive into more specific resources if you need it.\n",
    "\n",
    "##### Next Steps\n",
    "\n",
    "Now that you have learned about calculus, statistics, probability and\n",
    "linear algebra, you should be good to dive into more specialized content\n",
    "like seminal books in machine and deep learning (for instance, Bishop,\n",
    "Christopher M. Pattern recognition and machine learning. springer, 2006,\n",
    "or Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. Deep learning.\n",
    "MIT press, 2016) .\n",
    "\n",
    "However, I recommend to keep a focus on practice while you continue to\n",
    "learn the theory. I like the vision of Rachel Thomas, co-founder and\n",
    "researcher at [Fast.ai](https://www.fast.ai/) about the ‘top-down’\n",
    "approach to learn deep learning (e.g.:\n",
    "https://www.fast.ai/2016/10/08/teaching-philosophy/): you start\n",
    "experimenting and building, and then you dive into the theory when you\n",
    "encounter limitations. This is opposed to the more traditional\n",
    "‘bottom-up’ approach where you start with the foundations and then go to\n",
    "the applications.\n",
    "\n",
    "This book is a bit between these two approaches: we start from the\n",
    "basics and move to more advanced concepts, but we try to use code and\n",
    "get our hands dirty from the beginning. The hands-on projects that you\n",
    "can find at the end of each chapter are also designed to show that you\n",
    "can use code to get more insights. The idea is that, when you study a\n",
    "theoretical concept, you can ask yourself: ‘is there a way to use code\n",
    "to verify or illustrate this concept?’\n",
    "\n",
    "My opinion is that you should go forth and back between theory (and the\n",
    "math behind) and practical applications. Don’t wait to master all the\n",
    "math to start building data science pipelines or machine learning\n",
    "algorithms in your own projects. I think that it will help you to stay\n",
    "motivated while you learn and to see the big picture more easily.\n",
    "\n",
    ""
   ]
  }],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
